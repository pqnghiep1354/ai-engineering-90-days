# =============================================================================
# Climate Q&A RAG System - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control!

# =============================================================================
# LLM API Keys (Required - at least one)
# =============================================================================

# OpenAI - Get key at https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic (Optional) - Get key at https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google AI (Optional) - Get key at https://aistudio.google.com/
GOOGLE_API_KEY=your-google-api-key-here

# =============================================================================
# Model Configuration
# =============================================================================

# LLM Model to use
# Options: gpt-4o-mini, gpt-4o, claude-3-haiku-20240307, claude-3-sonnet-20240229
LLM_MODEL=gpt-4o-mini

# Embedding Model
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-small

# Temperature for LLM (0.0 - 1.0)
LLM_TEMPERATURE=0.1

# Max tokens for response
LLM_MAX_TOKENS=2048

# =============================================================================
# Vector Database Configuration
# =============================================================================

# Vector DB Type: chroma (local) or pinecone (cloud)
VECTOR_DB_TYPE=chroma

# ChromaDB settings (for local development)
CHROMA_PERSIST_DIRECTORY=./data/chroma_db
CHROMA_COLLECTION_NAME=climate_documents

# Pinecone settings (for production)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=climate-qa

# =============================================================================
# RAG Configuration
# =============================================================================

# Number of documents to retrieve
RETRIEVER_TOP_K=5

# Chunk size for document splitting (in characters)
CHUNK_SIZE=1000

# Chunk overlap (in characters)
CHUNK_OVERLAP=200

# Enable reranking (true/false)
USE_RERANKER=true

# Reranker model
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Number of documents after reranking
RERANKER_TOP_K=3

# =============================================================================
# LangSmith Monitoring (Optional but recommended)
# =============================================================================

# Get API key at https://smith.langchain.com/
LANGCHAIN_API_KEY=ls__your-langsmith-api-key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=climate-qa-rag
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# =============================================================================
# Application Settings
# =============================================================================

# App Environment: development, staging, production
APP_ENV=development

# Debug mode
DEBUG=true

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# API settings
API_HOST=0.0.0.0
API_PORT=8000

# Streamlit settings
STREAMLIT_PORT=8501

# =============================================================================
# Feature Flags
# =============================================================================

# Enable conversation memory
ENABLE_MEMORY=true

# Enable query expansion
ENABLE_QUERY_EXPANSION=true

# Enable hybrid search (vector + keyword)
ENABLE_HYBRID_SEARCH=true

# Enable streaming responses
ENABLE_STREAMING=true

# =============================================================================
# Security (Production only)
# =============================================================================

# API Key for authentication (generate a secure random string)
# API_AUTH_KEY=your-secure-api-key

# CORS origins (comma-separated)
# CORS_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
